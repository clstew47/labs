{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and Text Analysis\n",
    "\n",
    "This assignment involves processing real e-mails, some of which are scams. Some of these scam e-mails have some offensive content. I don't think anything is worse than R-rated, but I just want to warn you that if you start reading the e-mail text, you might read something offensive. If that's a problem, feel free to e-mail me and we can talk about it more or you can skip the assignment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [re, :, 6, ., 1100, ,, disc, :, uniformitarian...\n",
       "1    [the, other, side, of, *, galicismos, *, *, ga...\n",
       "2    [re, :, equistar, deal, tickets, are, you, sti...\n",
       "3    [Hello, I, am, your, hot, lil, horny, toy., I,...\n",
       "4    [software, at, incredibly, low, prices, (, 86,...\n",
       "Name: Email Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from multiprocessing.pool import Pool\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_parquet('https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet')\n",
    "# raw data head\n",
    "df.head()\n",
    "\n",
    "# after splitting head\n",
    "tokens = df['Email Text'].str.split()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to clean the tokens, I would convert to lowercase, remove stop words including words like \"the\" and \"is\" since those are neutral words and would not be useful in detecting phishing emails. \n",
    "Additionally, I would remove punctuation and remove special characters. \n",
    "\n",
    "Then, to represent the emails, I would use Term Frequency-Inverse Document Frequency to assign weights to tokens based on their frequency in an email compared to their overall occurrence across all emails. This would emphasize important words while reducing the impact of the common words that occur. \n",
    "\n",
    "Finally, after generating the TF-IDF matrix, PCA can be used to reduce the dimensionality, retaining only the most informative features while eliminating redundancy. The reduced feature set is then used as input for a linear model. This utilizes the flexibility linear models while efficiently handling the high dimensionality of text data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. \n",
    "\n",
    "I aggregated all the emails into a single vector, and removed the punctuation and very common words (e.g. \"the\"). Run the below code chunk to open it, and use the Counter class to look at the most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_tokens.pickle', 'rb') as file:\n",
    "    all_tokens = pickle.load(file)\n",
    "    \n",
    "from collections import Counter\n",
    "token_count = Counter(all_tokens)\n",
    "token_freq = token_count.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the occurrences of tokens. What do you notice about the frequency of occurrence of different tokens? How does it look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of occurrences of tokens\n",
    "\n",
    "# open pickle file containing all tokens from dataset in read-binary mode\n",
    "with open('all_tokens.pickle', 'rb') as file:\n",
    "    all_tokens = pickle.load(file)\n",
    "    \n",
    "from collections import Counter\n",
    "# count freq of each unique token in 'all_tokens' list\n",
    "token_count = Counter(all_tokens)\n",
    "# these r the most common tokens and their frequencies as a list of tuples\n",
    "token_freq = token_count.most_common()\n",
    "\n",
    "# df with token frequency data\n",
    "gdf = pd.DataFrame(token_freq,columns=['token','count'])\n",
    "\n",
    "# plot histogram of occurrences of tokens\n",
    "gdf['count'].hist(grid=False,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48691.000000\n",
       "mean         5.687889\n",
       "std         27.717476\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max       1365.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe numerical data of token frequency\n",
    "gdf['count'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I noticed from this is that most tokens appear only once. The token with the highest frequency is 1365 times. The average frequency is only 5.68 times, thus most of the tokens have lower frequencies at about 10 times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. \n",
    "\n",
    "Load `Phishing_clean.parquet`. This is the text from the e-mails broken into the most common 2,711 tokens and one-hot-encoded as features/covariates. So each row is an e-mail, the `Email Type` takes the value 1 if it's a scam and 0 otherwise, and every other column is a word or symbol that occurs in at least 15 e-mails.\n",
    "\n",
    "1. Perform an 80/20 train-test split of the data.\n",
    "2. Run a regression of $y$ on the one-hot-encoded emails. What is the $R^2$ on the test set? On the training set?\n",
    "3. What words have the largest coefficients in absolute value and most strongly influence predictions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.6144860820476118\n",
      "test:  -0.000268384328047544\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('Phishing_clean.parquet')\n",
    "\n",
    "# separate target variable (email type) from features\n",
    "y = df['Email Type']\n",
    "X = df.drop('Email Type',axis=1)\n",
    "\n",
    "## 1. split training and test sets \n",
    "# 80% -> training, 20% -> test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=125)\n",
    "\n",
    "## 2. train linear regression model on training data\n",
    "\n",
    "# fit linear regression model on training data\n",
    "lm_0 = LinearRegression(fit_intercept=False).fit(X_train,y_train)\n",
    "\n",
    "# use trained model to make predictions on test and training data\n",
    "y_hat_test_0 = lm_0.predict(X_test)\n",
    "y_hat_train_0 = lm_0.predict(X_train)\n",
    "\n",
    "# print r-squared scores for model on the training and test data \n",
    "# shows how well model fits with the data\n",
    "print('train: ', r2_score(y_hat_train_0,y_train) )\n",
    "print('test: ', r2_score(y_hat_test_0,y_test) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>1997-2002</td>\n",
       "      <td>-1.514772e+13</td>\n",
       "      <td>1.514772e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>pudge.</td>\n",
       "      <td>1.514772e+13</td>\n",
       "      <td>1.514772e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002</td>\n",
       "      <td>1.448712e+13</td>\n",
       "      <td>1.448712e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>000</td>\n",
       "      <td>-1.151892e+13</td>\n",
       "      <td>1.151892e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2005</td>\n",
       "      <td>-9.766916e+12</td>\n",
       "      <td>9.766916e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>soon</td>\n",
       "      <td>-1.974106e-04</td>\n",
       "      <td>1.974106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>thing</td>\n",
       "      <td>1.831055e-04</td>\n",
       "      <td>1.831055e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>say</td>\n",
       "      <td>-1.220703e-04</td>\n",
       "      <td>1.220703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>science</td>\n",
       "      <td>-6.866455e-05</td>\n",
       "      <td>6.866455e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>greg</td>\n",
       "      <td>2.288818e-05</td>\n",
       "      <td>2.288818e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2711 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable         value           abs\n",
       "2223  1997-2002 -1.514772e+13  1.514772e+13\n",
       "2224     pudge.  1.514772e+13  1.514772e+13\n",
       "6          2002  1.448712e+13  1.448712e+13\n",
       "96          000 -1.151892e+13  1.151892e+13\n",
       "340        2005 -9.766916e+12  9.766916e+12\n",
       "...         ...           ...           ...\n",
       "1052       soon -1.974106e-04  1.974106e-04\n",
       "319       thing  1.831055e-04  1.831055e-04\n",
       "254         say -1.220703e-04  1.220703e-04\n",
       "512     science -6.866455e-05  6.866455e-05\n",
       "989        greg  2.288818e-05  2.288818e-05\n",
       "\n",
       "[2711 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3. \n",
    "\n",
    "# create df to store the variable names and their coefficient vals from trained model  \n",
    "rdf = pd.DataFrame({'variable':lm_0.feature_names_in_ , 'value':lm_0.coef_})\n",
    "\n",
    "# stores absolute value of coefficient\n",
    "rdf['abs'] = np.abs(rdf['value'])\n",
    "# sort by abs col in descending order to highlight important variables\n",
    "rdf.sort_values('abs',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words with the largest coefficients in absolute value that most strongly influence the predictions are: \n",
    "- 1997-2002\n",
    "- pudge.\n",
    "- 2002\n",
    "- 000\n",
    "- 2005\n",
    "\n",
    "These are the variables with the large absolute coefficients, meaning that they have a significant influence on whether an email is detected as phishing or not. The positive or negative sign of the coefficients indicates whether the presence of these tokens increases or decreases the likelihood of an email being classified as phishing. \n",
    "\n",
    "In particular, 1997-2002 and 000 have negative coefficients, indicating that they may decrease the likelihood of the email being classified as phishing. However, pudge. and 2005 have large positive coefficients, indicating that they may increase the likelihood of the email being classified as phishing. \n",
    "\n",
    "These findings indicate some unusual and potentially noisy tokens that might not necessary be meaningful in a real-world context but strongly correlated with phishing emails in the data. Thus, it's important to investigate these tokens are valid signals or if they represent noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. \n",
    "\n",
    "Take the matrix of one-hot-encoded tokens (the data, less the outcome variable, `Email Type`) and perform a principal components analysis decomposition with two components. Plot the first two principal components in a scatter plot, and hue the points by whether they are a phishing scam or not. Do you notice any patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.\n",
    "\n",
    "Run a linear regression of $y$ on the first 2,610 principal components of $X$. What is the $R^2$ on the training and test sets? (I used cross validation to determine that 2,610 was approximately optimal, but not all 2,711 components.)\n",
    "\n",
    "How does this performance compare to the linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.\n",
    "\n",
    "Explain briefly in your own words what the advantage is in using the principal components to run this high-dimensional regression, rather than the original data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".txt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
